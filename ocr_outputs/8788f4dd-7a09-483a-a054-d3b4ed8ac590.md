To address these limitations, Large Language Models (LLMs) have recently demonstrated remarkable capabilities in naturallanguageunderstandingandgeneration,offering new potentialforintelligent retrieval systems. However,general-purposeLLMs struggle when applied directly to patent documents, which combine structured metadata with dense, domainspecific technical descriptions.They oftenlack sufficient domain knowledge and fail to grasp specialized terminologies. Retrieval-Augmented Generation (RAG) technology has emerged as a cutting-edge solution by combining LLMs with external document retrieval systems, enabling the model to dynamically incorporate relevant knowledge during generation. This significantly enhances both semantic understanding and precision in specialized tasks such as patent analysis [2].



司号In this work, we propose an automatic patent literature retrieval system based on the LLMRAG framework.Our goal is to integratethe deep semantic modeling capabilitiesofLLMs withthebroad coverageandefficiencyofvector-basedretrieval,therebyenhancingthe performance of patentdocument matching,semanticrelevance scoring,and cross-domain similarity analysis. The system consists ofthree main components: (1)a patent data preprocessing and normalization module to standardize structure and clean semantic noise; (2)anefficient vector retrieval systembuilt on dense embeddings to supportfast semantic matching;and (3) a RAG-enhanced query generation module, whichsynthesizes structured responses based on retrieved knowledge.



We evaluate our system using a large-scale dataset provided by Google Patents, covering millionsofreal-worldpatententriessubmittedbetween_2006and_2024across multiple jurisdictions, including the United States Patent and Trademark Office (USPTO). The dataset includes keyfieldssuch as patent type, application number, title, application date, legal status,and technical domain, forming a comprehensive foundation for training and evaluation.

### 2. Literature Review 

Inthedomainofintelligentinformationretrievalandtechnologyintelligencemining,patent literature is a key repository of global innovation with high strategic value. Accurate and efficientretrievalsupports enterprise technologyplanning, competitive monitoring, and researchinstitutions in tracking cutting-edgedevelopments. However,patenttextsfeature complexstructures,domain-specific terminology,and semanticambiguities,often spanning multiple disciplines. These characteristics limit the performance of traditional keyword- or rulebased retrieval, leading to low recall and poor semantic relevance in large-scale patent datasets.

Recentadvances in largelanguage models(LLMs)haverevealed strong potentialfor patent retrieval, yet challenges remain, including limited domain adaptation and semantic drift.Retrieval-Augmented Generation(RAG) offersa promising solution by combining external knowledge base access with the contextual reasoning of generative models. This integration improvesinterpretationof complextechnical semanticsandboostsrecallof cross-domain,high-relevance patents, addressing core limitations of existing retrieval approaches.

Kyung-Yul Lee et al [3]. introduce PAI-NET, a retrieval-augmented patent network that embedsprior-artrelationshipsintodeepsimilarity learning,outperformingstate-of-the-art models by15% on USPD and KPRIS datasets. Runtao Ren et al [4]. propose MQG-RFM, a lightweight Data-to-Tune framework that uses LLMs to generate diverse synthetic queries and fine-tunes retrieval models for IP Q&A. By uniting prompt-engineered generation with hardnegative mining, it boosts retrieval accuracy $185-262\%$ and generation quality $14-53\%$ on Taiwan patent datasets without architectural overhaul. Already adopted by ScholarMate, this approachofferssmall agencies acost-effective pathtorobust patent intelligence.

QiushiXiongetal[5]. presentMemGraph,a memory-graph-enhanced methodthat prompts LLMs to traverse their parametric memory for patent matching. By linking entities to ontologies, it boosts semantic comprehension and surpasses keyword-only baselines, yielding a 17.68% improvement on PatentMatch. The approach generalizes across LLMs and clarifies the value of hierarchical reasoning for IP management.



Sha Li etal [6]. present PRO, a faithful patent-response system that couplesa domainspecificLLMwith a procedural-knowledgegraphand retrieval-augmentedgeneration. By encoding legal interpretations and retrieving case-relevant facts, PRO outperforms GPT-4 by 